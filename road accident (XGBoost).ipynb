{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a253d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darla\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\darla\\AppData\\Local\\Temp/ipykernel_17132/2088869281.py:31: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  victime.var()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7006002400960384\n",
      "0.6564000548772122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "carac = pd.read_csv(\"C:/Users/darla/Desktop/Logements data/Base d'apprentissage/carac.csv\",sep=';')\n",
    "lieux = pd.read_csv(\"C:/Users/darla/Desktop/Logements data/Base d'apprentissage/lieux.csv\",sep=';')\n",
    "veh = pd.read_csv(\"C:/Users/darla/Desktop/Logements data/Base d'apprentissage/veh.csv\",sep=';')\n",
    "vict = pd.read_csv(\"C:/Users/darla/Desktop/Logements data/Base d'apprentissage/vict.csv\",sep=';')\n",
    "\n",
    "victime = vict.merge(veh,on=['Num_Acc','num_veh'])\n",
    "accident = carac.merge(lieux,on = 'Num_Acc')\n",
    "victime = victime.merge(accident,on='Num_Acc')\n",
    "\n",
    "nans = ['v1','v2','lartpc','larrout','locp','etatp','actp','voie','pr1','pr','place']\n",
    "\n",
    "victime = victime.drop(columns = nans)\n",
    "\n",
    "victime = victime.dropna()\n",
    "\n",
    "victime.corr()\n",
    "victime.var()\n",
    "\n",
    "victime = victime.drop(columns=['an'])\n",
    "\n",
    "hrmn=pd.cut(victime['hrmn'],24,labels=[str(i) for i in range(0,24)])\n",
    "victime['hrmn']=hrmn.values\n",
    "\n",
    "# On extrait du tableau la latitude et la longitude\n",
    "\n",
    "X_lat = victime['lat']\n",
    "X_long = victime['long']\n",
    "\n",
    "# On définit tous nos points à classifier\n",
    "\n",
    "X_cluster = np.array((list(zip(X_lat, X_long))))\n",
    "\n",
    "# Kmeans nous donne pour chaque point la catégorie associée\n",
    "\n",
    "clustering = KMeans(n_clusters=15, random_state=0)\n",
    "clustering.fit(X_cluster)\n",
    "\n",
    "# Enfin on ajoute les catégories dans la base d'entraînement\n",
    "\n",
    "geo = pd.Series(clustering.labels_)\n",
    "victime['geo'] = geo\n",
    "\n",
    "y = victime['grav']\n",
    "\n",
    "features = ['catu','sexe','trajet','secu',\n",
    "            'catv','an_nais','mois',\n",
    "            'occutc','obs','obsm','choc','manv',\n",
    "            'lum','agg','int','atm','col','gps',\n",
    "            'catr','circ','vosp','prof','plan',\n",
    "            'surf','infra','situ','hrmn','geo']\n",
    "\n",
    "X_train = pd.get_dummies(victime[features].astype(str))\n",
    "\n",
    "# On redécoupe la base en train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train,y)\n",
    "\n",
    "\n",
    "# On crée le modèle :\n",
    "\n",
    "model_boosting = GradientBoostingClassifier(loss=\"deviance\",\n",
    "    learning_rate=0.2,\n",
    "    max_depth=5,\n",
    "    max_features=\"sqrt\",\n",
    "    subsample=0.95,\n",
    "    n_estimators=200)\n",
    "\n",
    "# L'entraînement débute :\n",
    "\n",
    "model_boosting.fit(X_train, y_train)\n",
    "\n",
    "# On calcul les prédictions\n",
    "predictions_test_xgb = model_boosting.predict(X_test)\n",
    "predictions_train_xgb = model_boosting.predict(X_train)\n",
    "\n",
    "# On affiche les résultats :\n",
    "\n",
    "train_acc = accuracy_score(y_train, predictions_train_xgb)\n",
    "print(train_acc)\n",
    "\n",
    "test_acc = accuracy_score(y_test, predictions_test_xgb)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0898a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
